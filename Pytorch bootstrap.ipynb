{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = np.genfromtxt('../input/xxx/train.csv',delimiter=\",\")\ntest = np.genfromtxt(\"../input/xxx/test.csv\",delimiter=\",\")","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class NeuralNet(torch.nn.Module):\n    def __init__(self, lrate,loss_fn,in_size,out_size,device,penalty=0):\n        \"\"\"\n        Initialize the layers of your neural network\n\n        @param lrate: The learning rate for the model.\n        @param loss_fn: A loss function defined in the following way:\n            @param yhat - an (N,out_size) tensor\n            @param y - an (N,) tensor\n            @return l(x,y) an () tensor that is the mean loss\n        @param in_size: Dimension of input\n        @param out_size: Dimension of output\n        \"\"\"\n        super(NeuralNet, self).__init__()\n        self.loss_fn = loss_fn\n        self.lrate = lrate\n        self.loss_fn = loss_fn\n        self.device=device\n        self.conv = torch.nn.Sequential(\n            \n            )\n        self.model = torch.nn.Sequential(\n            )\n        self.optim = torch.optim.Adam([x for x in self.model.parameters()] + [x for x in self.conv.parameters()],lr=self.lrate,weight_decay=penalty)\n\n    def forward(self, x):\n        \"\"\" A forward pass of your neural net (evaluates f(x)).\n\n        @param x: an (N, in_size) torch tensor\n\n        @return y: an (N, out_size) torch tensor of output from the network\n        \"\"\"\n\n    def step(self, x,y):\n        \"\"\"\n        Performs one gradient step through a batch of data x with labels y\n        @param x: an (N, in_size) torch tensor\n        @param y: an (N,) torch tensor\n        @return L: total empirical risk (mean of losses) at this time step as a float\n        \"\"\"\n        self.optim.zero_grad()\n        output = self.forward(x)\n        loss = self.loss_fn(output,y)\n\n        loss.backward()\n        self.optim.step()\n        return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_accuracies(predicted_labels,dev_set,dev_labels):\n    yhats = predicted_labels\n    if len(yhats) != len(dev_labels):\n        print(\"Lengths of predicted labels don't match length of actual labels\", len(yhats),len(dev_labels))\n        return 0.,0.,0.,0.\n    accuracy = np.mean(yhats == dev_labels)\n    tp = np.sum([yhats[i] == dev_labels[i] and yhats[i] == 1 for i in range(len(dev_labels))])\n    precision = tp / np.sum([yhats[i]==1 for i in range(len(dev_labels))])\n    recall = tp / (np.sum([yhats[i] != dev_labels[i] and yhats[i] == 0 for i in range(len(dev_labels))]) + tp)\n    f1 = 2 * (precision * recall) / (precision + recall)\n    \n    return accuracy,f1,precision,recall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n\nparams = {'batch_size': 25,\n          'shuffle': True,\n          'num_workers' : 8}\n\ntrain_data = torch.tensor(train_d, dtype=torch.float)\ntrain_labels = torch.tensor(train_l, dtype=torch.long)\ntest_data = torch.tensor(test_d,dtype=torch.float)\n\ntrainset = torch.utils.data.TensorDataset(train_data, train_labels)\ntrainloader=torch.utils.data.DataLoader(trainset, **params)\nnet = NeuralNet(1e-4,torch.nn.CrossEntropyLoss(),train_data.shape[1],10,device,penalty=.01)\nyhats = np.zeros((test_data.shape[0],))\n\nfor epoch in range(5):\n    for inputs,lbls in trainloader:\n        inputs, lbls = inputs.float().to(device), lbls.long().to(device)\n        cur_loss = net.step(inputs,lbls)\nfor i in range(test_data.shape[0]): #dev_set.shape[0]\n    inputs = test_data[i,:].to(device)\n    out = net.forward(inputs)\n    max_val, max_idx = out[0].max(0)\n    yhats[i] = max_idx.item()\n\naccuracy,f1,precision,recall = compute_accuracies(yhats,test_data,test_l)\nprint(\"accuracy: {}\".format(accuracy))\nprint(\"f1: {}\".format(f1))\nprint(\"precision: {}\".format(precision))\nprint(\"recall: {}\".format(recall))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}