{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/mnist-original/mnist-original.mat\n/kaggle/input/mnist-in-csv/mnist_train.csv\n/kaggle/input/mnist-in-csv/mnist_test.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = np.genfromtxt('../input/mnist-in-csv/mnist_train.csv',delimiter=\",\")\ntest = np.genfromtxt(\"../input/mnist-in-csv/mnist_test.csv\",delimiter=\",\")","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(train)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"       0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n0      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n1      5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n3      4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n4      1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n59996  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n59997  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n59998  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n59999  6.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n60000  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n\n       778  779  780  781  782  783  784  \n0      NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n...    ...  ...  ...  ...  ...  ...  ...  \n59996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n59997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n59998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n59999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n60000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[60001 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n      <th>784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59996</th>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>59997</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>59998</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>59999</th>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>60000</th>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>60001 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_d = train[1:,1:]\ntrain_l = train[1:,0]\ntest_d = test[1:,1:]\ntest_l = test[1:,0]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralNet(torch.nn.Module):\n    def __init__(self, lrate,loss_fn,in_size,out_size,device,penalty=0):\n        \"\"\"\n        Initialize the layers of your neural network\n\n        @param lrate: The learning rate for the model.\n        @param loss_fn: A loss function defined in the following way:\n            @param yhat - an (N,out_size) tensor\n            @param y - an (N,) tensor\n            @return l(x,y) an () tensor that is the mean loss\n        @param in_size: Dimension of input\n        @param out_size: Dimension of output\n        \"\"\"\n        super(NeuralNet, self).__init__()\n        self.loss_fn = loss_fn\n        self.lrate = lrate\n        self.loss_fn = loss_fn\n        self.device=device\n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=1, out_channels=10,kernel_size=5).cuda(device),\n            torch.nn.ReLU().cuda(device),\n            torch.nn.MaxPool2d(2).cuda(device),\n            torch.nn.Conv2d(10, 20, kernel_size=5).cuda(device),\n            torch.nn.ReLU().cuda(device),\n            torch.nn.MaxPool2d(2).cuda(device)\n            )\n        self.model = torch.nn.Sequential(\n            torch.nn.Linear(320,50).cuda(device),\n            torch.nn.ReLU().cuda(device),\n            torch.nn.Linear(50,10).cuda(device),\n            torch.nn.LogSoftmax().cuda(device)\n            )\n        self.optim = torch.optim.Adam([x for x in self.model.parameters()] + [x for x in self.conv.parameters()],lr=self.lrate,weight_decay=penalty)\n\n    def forward(self, x):\n        \"\"\" A forward pass of your neural net (evaluates f(x)).\n\n        @param x: an (N, in_size) torch tensor\n\n        @return y: an (N, out_size) torch tensor of output from the network\n        \"\"\"\n        x = x.view(-1,1,28,28)\n        x= self.conv(x)\n        #print(x.shape)\n        x = x.view(-1, 20*4*4)\n        return torch.nn.functional.log_softmax(self.model(x),dim=-1)\n\n    def step(self, x,y):\n        \"\"\"\n        Performs one gradient step through a batch of data x with labels y\n        @param x: an (N, in_size) torch tensor\n        @param y: an (N,) torch tensor\n        @return L: total empirical risk (mean of losses) at this time step as a float\n        \"\"\"\n        self.optim.zero_grad()\n        output = self.forward(x)\n        loss = self.loss_fn(output,y)\n\n        loss.backward()\n        self.optim.step()\n        return loss\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_accuracies(predicted_labels,dev_set,dev_labels):\n    yhats = predicted_labels\n    if len(yhats) != len(dev_labels):\n        print(\"Lengths of predicted labels don't match length of actual labels\", len(yhats),len(dev_labels))\n        return 0.,0.,0.,0.\n    accuracy = np.mean(yhats == dev_labels)\n    tp = np.sum([yhats[i] == dev_labels[i] and yhats[i] == 1 for i in range(len(dev_labels))])\n    precision = tp / np.sum([yhats[i]==1 for i in range(len(dev_labels))])\n    recall = tp / (np.sum([yhats[i] != dev_labels[i] and yhats[i] == 0 for i in range(len(dev_labels))]) + tp)\n    f1 = 2 * (precision * recall) / (precision + recall)\n    \n    return accuracy,f1,precision,recall","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n\nparams = {'batch_size': 25,\n          'shuffle': True,\n          'num_workers' : 8}\n\ntrain_data = torch.tensor(train_d, dtype=torch.float)\ntrain_labels = torch.tensor(train_l, dtype=torch.long)\ntest_data = torch.tensor(test_d,dtype=torch.float)\n\ntrainset = torch.utils.data.TensorDataset(train_data, train_labels)\ntrainloader=torch.utils.data.DataLoader(trainset, **params)\nnet = NeuralNet(1e-4,torch.nn.CrossEntropyLoss(),train_data.shape[1],10,device,penalty=.01)\nyhats = np.zeros((test_data.shape[0],))\n\nfor epoch in range(5):\n    for inputs,lbls in trainloader:\n        inputs, lbls = inputs.float().to(device), lbls.long().to(device)\n        cur_loss = net.step(inputs,lbls)\nfor i in range(test_data.shape[0]): #dev_set.shape[0]\n    inputs = test_data[i,:].to(device)\n    out = net.forward(inputs)\n    max_val, max_idx = out[0].max(0)\n    yhats[i] = max_idx.item()\n\naccuracy,f1,precision,recall = compute_accuracies(yhats,test_data,test_l)\nprint(\"accuracy: {}\".format(accuracy))\nprint(\"f1: {}\".format(f1))\nprint(\"precision: {}\".format(precision))\nprint(\"recall: {}\".format(recall))\n","execution_count":11,"outputs":[{"output_type":"stream","text":"cuda:0\nepoch 0\nepoch 1\nepoch 2\nepoch 3\nepoch 4\nstarting testing\naccuracy: 0.983\nf1: 0.9928507596067918\nprecision: 0.9955197132616488\nrecall: 0.9901960784313726\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Compeleted with following statistics\n\naccuracy: 0.983\n\nf1: 0.9928507596067918\n\nprecision: 0.9955197132616488\n\nrecall: 0.9901960784313726"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}