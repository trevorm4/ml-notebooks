{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN with MNIST",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLBr7_O6NOco",
        "colab_type": "code",
        "outputId": "ea57fe0b-52fb-43a4-dc49-c9e272bed8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root='.', train=True, download=True, transform=transforms.Compose(\n",
        "            [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ))\n",
        "loader = torch.utils.data.DataLoader(mnist_trainset,batch_size=64,num_workers=16)\n",
        "num_epochs = 300\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4wGmnyTPQlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,latent_dim,image_dim):\n",
        "    super(Generator,self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.image_dim = image_dim\n",
        "    def block(in_feat, out_feat, normalize=True):\n",
        "        layers = [nn.Linear(in_feat, out_feat)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        *block(latent_dim, 128, normalize=False),\n",
        "        *block(128, 256),\n",
        "        *block(256, 512),\n",
        "        *block(512, 1024),\n",
        "        nn.Linear(1024, image_dim**2),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = x.view(-1,self.latent_dim)\n",
        "    out = self.model(x)\n",
        "    out = out.view(-1,self.image_dim, self.image_dim)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKPG9I8bSCgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,image_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(image_shape ** 2, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "\n",
        "        return validity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl74Y2qArS3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = Generator(128,28).cuda()\n",
        "discrim = Discriminator(28).cuda()\n",
        "adversarial_loss = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akoxCqvYhREL",
        "colab_type": "code",
        "outputId": "4171e828-afb3-4af8-a25e-f09f505bba5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "gen_optim = torch.optim.Adam(gen.parameters(),lr=1e-4)\n",
        "discrim_optim = torch.optim.Adam(discrim.parameters(),lr=1e-4)\n",
        "latent_dim = 128\n",
        "for epoch in range(num_epochs):\n",
        "  print(epoch)\n",
        "  for i, data in enumerate(loader):\n",
        "    img, _ = data\n",
        "    img = Variable(img.detach().to(device))\n",
        "    valid = Variable(torch.Tensor(img.shape[0],1).fill_(1.0),requires_grad=False).cuda()\n",
        "    invalid = Variable(torch.Tensor(img.shape[0],1).fill_(0.0),requires_grad=False).cuda()\n",
        "    \n",
        "    # Train Discriminator\n",
        "    discrim_optim.zero_grad()\n",
        "    fake_imgs = gen(torch.randn((img.shape[0],latent_dim)).to(device)).detach()\n",
        "    real_out = discrim(img)\n",
        "    fake_out = discrim(fake_imgs)\n",
        "    real_loss = adversarial_loss(real_out,valid)\n",
        "    fake_loss = adversarial_loss(fake_out,invalid)\n",
        "    d_loss = (real_loss + fake_loss) / 2\n",
        "    d_loss.backward()\n",
        "    discrim_optim.step()\n",
        "\n",
        "    # Train Generator\n",
        "    gen_optim.zero_grad()\n",
        "    noise = Variable(torch.Tensor(np.random.normal(0, 1, (img.shape[0], latent_dim)))).to(device)\n",
        "    out = gen(noise)\n",
        "    discrim_out = discrim(out)\n",
        "    g_loss = adversarial_loss(discrim_out,valid)\n",
        "    \n",
        "    g_loss.backward()\n",
        "    gen_optim.step()\n",
        "\n",
        "    if epoch % 5 == 0 and i % 100 == 0:\n",
        "      print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, num_epochs, i, len(loader), d_loss.item(), g_loss.item())\n",
        "        )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[Epoch 0/300] [Batch 0/938] [D loss: 0.684732] [G loss: 0.678743]\n",
            "[Epoch 0/300] [Batch 100/938] [D loss: 0.442549] [G loss: 0.861359]\n",
            "[Epoch 0/300] [Batch 200/938] [D loss: 0.259801] [G loss: 1.581638]\n",
            "[Epoch 0/300] [Batch 300/938] [D loss: 0.535804] [G loss: 1.070444]\n",
            "[Epoch 0/300] [Batch 400/938] [D loss: 0.701955] [G loss: 0.454073]\n",
            "[Epoch 0/300] [Batch 500/938] [D loss: 0.446569] [G loss: 1.633453]\n",
            "[Epoch 0/300] [Batch 600/938] [D loss: 0.241232] [G loss: 2.955877]\n",
            "[Epoch 0/300] [Batch 700/938] [D loss: 0.246619] [G loss: 2.038481]\n",
            "[Epoch 0/300] [Batch 800/938] [D loss: 0.437409] [G loss: 1.303104]\n",
            "[Epoch 0/300] [Batch 900/938] [D loss: 0.297826] [G loss: 1.993575]\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "[Epoch 5/300] [Batch 0/938] [D loss: 0.148640] [G loss: 4.210704]\n",
            "[Epoch 5/300] [Batch 100/938] [D loss: 0.079359] [G loss: 5.269105]\n",
            "[Epoch 5/300] [Batch 200/938] [D loss: 0.081690] [G loss: 5.812726]\n",
            "[Epoch 5/300] [Batch 300/938] [D loss: 0.045823] [G loss: 4.859176]\n",
            "[Epoch 5/300] [Batch 400/938] [D loss: 0.046965] [G loss: 6.672751]\n",
            "[Epoch 5/300] [Batch 500/938] [D loss: 0.036784] [G loss: 5.025139]\n",
            "[Epoch 5/300] [Batch 600/938] [D loss: 0.095484] [G loss: 6.387162]\n",
            "[Epoch 5/300] [Batch 700/938] [D loss: 0.199220] [G loss: 5.953660]\n",
            "[Epoch 5/300] [Batch 800/938] [D loss: 0.053745] [G loss: 3.919158]\n",
            "[Epoch 5/300] [Batch 900/938] [D loss: 0.085891] [G loss: 4.435566]\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "[Epoch 10/300] [Batch 0/938] [D loss: 0.268345] [G loss: 5.107864]\n",
            "[Epoch 10/300] [Batch 100/938] [D loss: 0.099681] [G loss: 4.081362]\n",
            "[Epoch 10/300] [Batch 200/938] [D loss: 0.476828] [G loss: 5.607050]\n",
            "[Epoch 10/300] [Batch 300/938] [D loss: 0.098545] [G loss: 4.302000]\n",
            "[Epoch 10/300] [Batch 400/938] [D loss: 0.099689] [G loss: 5.598774]\n",
            "[Epoch 10/300] [Batch 500/938] [D loss: 0.073758] [G loss: 6.000438]\n",
            "[Epoch 10/300] [Batch 600/938] [D loss: 0.060386] [G loss: 3.669518]\n",
            "[Epoch 10/300] [Batch 700/938] [D loss: 0.042730] [G loss: 4.712494]\n",
            "[Epoch 10/300] [Batch 800/938] [D loss: 0.116763] [G loss: 6.467869]\n",
            "[Epoch 10/300] [Batch 900/938] [D loss: 0.064252] [G loss: 5.378348]\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "[Epoch 15/300] [Batch 0/938] [D loss: 0.175243] [G loss: 6.804303]\n",
            "[Epoch 15/300] [Batch 100/938] [D loss: 0.050464] [G loss: 5.249175]\n",
            "[Epoch 15/300] [Batch 200/938] [D loss: 0.141580] [G loss: 5.144892]\n",
            "[Epoch 15/300] [Batch 300/938] [D loss: 0.093769] [G loss: 5.233784]\n",
            "[Epoch 15/300] [Batch 400/938] [D loss: 0.155996] [G loss: 3.241960]\n",
            "[Epoch 15/300] [Batch 500/938] [D loss: 0.116600] [G loss: 4.259042]\n",
            "[Epoch 15/300] [Batch 600/938] [D loss: 0.222024] [G loss: 4.679937]\n",
            "[Epoch 15/300] [Batch 700/938] [D loss: 0.113671] [G loss: 5.198047]\n",
            "[Epoch 15/300] [Batch 800/938] [D loss: 0.078378] [G loss: 5.141055]\n",
            "[Epoch 15/300] [Batch 900/938] [D loss: 0.062008] [G loss: 5.895498]\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "[Epoch 20/300] [Batch 0/938] [D loss: 0.105017] [G loss: 2.836253]\n",
            "[Epoch 20/300] [Batch 100/938] [D loss: 0.063776] [G loss: 7.163488]\n",
            "[Epoch 20/300] [Batch 200/938] [D loss: 0.139878] [G loss: 2.800092]\n",
            "[Epoch 20/300] [Batch 300/938] [D loss: 0.166025] [G loss: 6.152076]\n",
            "[Epoch 20/300] [Batch 400/938] [D loss: 0.095858] [G loss: 5.264819]\n",
            "[Epoch 20/300] [Batch 500/938] [D loss: 0.099699] [G loss: 5.503609]\n",
            "[Epoch 20/300] [Batch 600/938] [D loss: 0.100323] [G loss: 3.363110]\n",
            "[Epoch 20/300] [Batch 700/938] [D loss: 0.194313] [G loss: 4.906124]\n",
            "[Epoch 20/300] [Batch 800/938] [D loss: 0.053403] [G loss: 5.081097]\n",
            "[Epoch 20/300] [Batch 900/938] [D loss: 0.170623] [G loss: 3.507345]\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "[Epoch 25/300] [Batch 0/938] [D loss: 0.377585] [G loss: 4.717113]\n",
            "[Epoch 25/300] [Batch 100/938] [D loss: 0.084572] [G loss: 10.279670]\n",
            "[Epoch 25/300] [Batch 200/938] [D loss: 0.337609] [G loss: 5.081248]\n",
            "[Epoch 25/300] [Batch 300/938] [D loss: 0.118054] [G loss: 5.117877]\n",
            "[Epoch 25/300] [Batch 400/938] [D loss: 0.263553] [G loss: 6.528524]\n",
            "[Epoch 25/300] [Batch 500/938] [D loss: 0.441556] [G loss: 5.691531]\n",
            "[Epoch 25/300] [Batch 600/938] [D loss: 0.092508] [G loss: 4.270050]\n",
            "[Epoch 25/300] [Batch 700/938] [D loss: 0.132367] [G loss: 4.651586]\n",
            "[Epoch 25/300] [Batch 800/938] [D loss: 0.056440] [G loss: 4.791575]\n",
            "[Epoch 25/300] [Batch 900/938] [D loss: 0.148353] [G loss: 3.944892]\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "[Epoch 30/300] [Batch 0/938] [D loss: 0.105151] [G loss: 9.992415]\n",
            "[Epoch 30/300] [Batch 100/938] [D loss: 0.124469] [G loss: 4.856032]\n",
            "[Epoch 30/300] [Batch 200/938] [D loss: 0.205033] [G loss: 3.606864]\n",
            "[Epoch 30/300] [Batch 300/938] [D loss: 0.093706] [G loss: 4.546491]\n",
            "[Epoch 30/300] [Batch 400/938] [D loss: 0.090409] [G loss: 5.850881]\n",
            "[Epoch 30/300] [Batch 500/938] [D loss: 0.218550] [G loss: 6.636803]\n",
            "[Epoch 30/300] [Batch 600/938] [D loss: 0.168642] [G loss: 2.482380]\n",
            "[Epoch 30/300] [Batch 700/938] [D loss: 0.166261] [G loss: 3.920880]\n",
            "[Epoch 30/300] [Batch 800/938] [D loss: 0.064975] [G loss: 2.987715]\n",
            "[Epoch 30/300] [Batch 900/938] [D loss: 0.188016] [G loss: 3.459399]\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "[Epoch 35/300] [Batch 0/938] [D loss: 0.206510] [G loss: 3.579830]\n",
            "[Epoch 35/300] [Batch 100/938] [D loss: 0.049963] [G loss: 3.916219]\n",
            "[Epoch 35/300] [Batch 200/938] [D loss: 0.309370] [G loss: 3.684193]\n",
            "[Epoch 35/300] [Batch 300/938] [D loss: 0.082698] [G loss: 4.140370]\n",
            "[Epoch 35/300] [Batch 400/938] [D loss: 0.153362] [G loss: 3.429070]\n",
            "[Epoch 35/300] [Batch 500/938] [D loss: 0.283198] [G loss: 4.180407]\n",
            "[Epoch 35/300] [Batch 600/938] [D loss: 0.106855] [G loss: 5.074037]\n",
            "[Epoch 35/300] [Batch 700/938] [D loss: 0.310892] [G loss: 3.083095]\n",
            "[Epoch 35/300] [Batch 800/938] [D loss: 0.219983] [G loss: 3.754186]\n",
            "[Epoch 35/300] [Batch 900/938] [D loss: 0.288416] [G loss: 4.159441]\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "[Epoch 40/300] [Batch 0/938] [D loss: 0.327265] [G loss: 4.868783]\n",
            "[Epoch 40/300] [Batch 100/938] [D loss: 0.061511] [G loss: 5.181507]\n",
            "[Epoch 40/300] [Batch 200/938] [D loss: 0.182664] [G loss: 3.995510]\n",
            "[Epoch 40/300] [Batch 300/938] [D loss: 0.269756] [G loss: 3.561446]\n",
            "[Epoch 40/300] [Batch 400/938] [D loss: 0.147002] [G loss: 3.921252]\n",
            "[Epoch 40/300] [Batch 500/938] [D loss: 0.114445] [G loss: 4.725412]\n",
            "[Epoch 40/300] [Batch 600/938] [D loss: 0.172551] [G loss: 2.968761]\n",
            "[Epoch 40/300] [Batch 700/938] [D loss: 0.137873] [G loss: 4.092556]\n",
            "[Epoch 40/300] [Batch 800/938] [D loss: 0.197033] [G loss: 7.072246]\n",
            "[Epoch 40/300] [Batch 900/938] [D loss: 0.165380] [G loss: 4.030954]\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "[Epoch 45/300] [Batch 0/938] [D loss: 0.210418] [G loss: 2.804291]\n",
            "[Epoch 45/300] [Batch 100/938] [D loss: 0.139230] [G loss: 4.600293]\n",
            "[Epoch 45/300] [Batch 200/938] [D loss: 0.230409] [G loss: 6.082776]\n",
            "[Epoch 45/300] [Batch 300/938] [D loss: 0.202191] [G loss: 2.733778]\n",
            "[Epoch 45/300] [Batch 400/938] [D loss: 0.158694] [G loss: 3.603445]\n",
            "[Epoch 45/300] [Batch 500/938] [D loss: 0.208056] [G loss: 5.290022]\n",
            "[Epoch 45/300] [Batch 600/938] [D loss: 0.147067] [G loss: 2.960737]\n",
            "[Epoch 45/300] [Batch 700/938] [D loss: 0.278626] [G loss: 3.977750]\n",
            "[Epoch 45/300] [Batch 800/938] [D loss: 0.116392] [G loss: 5.638008]\n",
            "[Epoch 45/300] [Batch 900/938] [D loss: 0.305856] [G loss: 3.768680]\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "[Epoch 50/300] [Batch 0/938] [D loss: 0.205106] [G loss: 3.694284]\n",
            "[Epoch 50/300] [Batch 100/938] [D loss: 0.118484] [G loss: 5.370963]\n",
            "[Epoch 50/300] [Batch 200/938] [D loss: 0.172834] [G loss: 3.489212]\n",
            "[Epoch 50/300] [Batch 300/938] [D loss: 0.247342] [G loss: 3.184388]\n",
            "[Epoch 50/300] [Batch 400/938] [D loss: 0.277616] [G loss: 5.211142]\n",
            "[Epoch 50/300] [Batch 500/938] [D loss: 0.146464] [G loss: 4.829882]\n",
            "[Epoch 50/300] [Batch 600/938] [D loss: 0.172040] [G loss: 3.768862]\n",
            "[Epoch 50/300] [Batch 700/938] [D loss: 0.105864] [G loss: 4.674597]\n",
            "[Epoch 50/300] [Batch 800/938] [D loss: 0.097767] [G loss: 2.482542]\n",
            "[Epoch 50/300] [Batch 900/938] [D loss: 0.140087] [G loss: 4.575034]\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "[Epoch 55/300] [Batch 0/938] [D loss: 0.537869] [G loss: 1.643369]\n",
            "[Epoch 55/300] [Batch 100/938] [D loss: 0.435768] [G loss: 4.238655]\n",
            "[Epoch 55/300] [Batch 200/938] [D loss: 0.127576] [G loss: 3.553720]\n",
            "[Epoch 55/300] [Batch 300/938] [D loss: 0.190720] [G loss: 3.172218]\n",
            "[Epoch 55/300] [Batch 400/938] [D loss: 0.144358] [G loss: 2.848423]\n",
            "[Epoch 55/300] [Batch 500/938] [D loss: 0.348969] [G loss: 2.939432]\n",
            "[Epoch 55/300] [Batch 600/938] [D loss: 0.140916] [G loss: 2.257898]\n",
            "[Epoch 55/300] [Batch 700/938] [D loss: 0.239924] [G loss: 3.151484]\n",
            "[Epoch 55/300] [Batch 800/938] [D loss: 0.187759] [G loss: 5.185381]\n",
            "[Epoch 55/300] [Batch 900/938] [D loss: 0.482303] [G loss: 4.918294]\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "[Epoch 60/300] [Batch 0/938] [D loss: 0.119182] [G loss: 3.180073]\n",
            "[Epoch 60/300] [Batch 100/938] [D loss: 0.098482] [G loss: 3.639215]\n",
            "[Epoch 60/300] [Batch 200/938] [D loss: 0.173834] [G loss: 3.605980]\n",
            "[Epoch 60/300] [Batch 300/938] [D loss: 0.270214] [G loss: 2.107965]\n",
            "[Epoch 60/300] [Batch 400/938] [D loss: 0.204788] [G loss: 3.869134]\n",
            "[Epoch 60/300] [Batch 500/938] [D loss: 0.496602] [G loss: 3.090674]\n",
            "[Epoch 60/300] [Batch 600/938] [D loss: 0.313324] [G loss: 3.716973]\n",
            "[Epoch 60/300] [Batch 700/938] [D loss: 0.220698] [G loss: 2.501954]\n",
            "[Epoch 60/300] [Batch 800/938] [D loss: 0.150888] [G loss: 4.485569]\n",
            "[Epoch 60/300] [Batch 900/938] [D loss: 0.174780] [G loss: 3.468920]\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "[Epoch 65/300] [Batch 0/938] [D loss: 0.204587] [G loss: 6.843729]\n",
            "[Epoch 65/300] [Batch 100/938] [D loss: 0.110471] [G loss: 5.009660]\n",
            "[Epoch 65/300] [Batch 200/938] [D loss: 0.277957] [G loss: 3.869028]\n",
            "[Epoch 65/300] [Batch 300/938] [D loss: 0.144482] [G loss: 3.908786]\n",
            "[Epoch 65/300] [Batch 400/938] [D loss: 0.240231] [G loss: 2.411154]\n",
            "[Epoch 65/300] [Batch 500/938] [D loss: 0.284059] [G loss: 2.433807]\n",
            "[Epoch 65/300] [Batch 600/938] [D loss: 0.160037] [G loss: 3.245551]\n",
            "[Epoch 65/300] [Batch 700/938] [D loss: 0.302748] [G loss: 3.191861]\n",
            "[Epoch 65/300] [Batch 800/938] [D loss: 0.329088] [G loss: 1.752418]\n",
            "[Epoch 65/300] [Batch 900/938] [D loss: 0.270585] [G loss: 2.461721]\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "[Epoch 70/300] [Batch 0/938] [D loss: 0.435217] [G loss: 2.843147]\n",
            "[Epoch 70/300] [Batch 100/938] [D loss: 0.180048] [G loss: 3.586439]\n",
            "[Epoch 70/300] [Batch 200/938] [D loss: 0.276737] [G loss: 2.359395]\n",
            "[Epoch 70/300] [Batch 300/938] [D loss: 0.244291] [G loss: 3.488856]\n",
            "[Epoch 70/300] [Batch 400/938] [D loss: 0.152029] [G loss: 3.746227]\n",
            "[Epoch 70/300] [Batch 500/938] [D loss: 0.374522] [G loss: 3.661937]\n",
            "[Epoch 70/300] [Batch 600/938] [D loss: 0.192486] [G loss: 3.149151]\n",
            "[Epoch 70/300] [Batch 700/938] [D loss: 0.225163] [G loss: 3.582692]\n",
            "[Epoch 70/300] [Batch 800/938] [D loss: 0.297848] [G loss: 2.399232]\n",
            "[Epoch 70/300] [Batch 900/938] [D loss: 0.355065] [G loss: 4.133506]\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "[Epoch 75/300] [Batch 0/938] [D loss: 0.241846] [G loss: 3.089151]\n",
            "[Epoch 75/300] [Batch 100/938] [D loss: 0.243534] [G loss: 4.358821]\n",
            "[Epoch 75/300] [Batch 200/938] [D loss: 0.238405] [G loss: 4.016113]\n",
            "[Epoch 75/300] [Batch 300/938] [D loss: 0.226424] [G loss: 5.212174]\n",
            "[Epoch 75/300] [Batch 400/938] [D loss: 0.234965] [G loss: 3.415634]\n",
            "[Epoch 75/300] [Batch 500/938] [D loss: 0.366401] [G loss: 2.784167]\n",
            "[Epoch 75/300] [Batch 600/938] [D loss: 0.110090] [G loss: 4.041863]\n",
            "[Epoch 75/300] [Batch 700/938] [D loss: 0.227294] [G loss: 3.165101]\n",
            "[Epoch 75/300] [Batch 800/938] [D loss: 0.053905] [G loss: 4.865599]\n",
            "[Epoch 75/300] [Batch 900/938] [D loss: 0.151984] [G loss: 3.433371]\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "[Epoch 80/300] [Batch 0/938] [D loss: 0.401924] [G loss: 3.886354]\n",
            "[Epoch 80/300] [Batch 100/938] [D loss: 0.160410] [G loss: 5.224945]\n",
            "[Epoch 80/300] [Batch 200/938] [D loss: 0.269484] [G loss: 2.969316]\n",
            "[Epoch 80/300] [Batch 300/938] [D loss: 0.171994] [G loss: 2.842954]\n",
            "[Epoch 80/300] [Batch 400/938] [D loss: 0.157529] [G loss: 3.239096]\n",
            "[Epoch 80/300] [Batch 500/938] [D loss: 0.164633] [G loss: 3.970276]\n",
            "[Epoch 80/300] [Batch 600/938] [D loss: 0.117115] [G loss: 2.987548]\n",
            "[Epoch 80/300] [Batch 700/938] [D loss: 0.135075] [G loss: 3.430853]\n",
            "[Epoch 80/300] [Batch 800/938] [D loss: 0.034526] [G loss: 4.768118]\n",
            "[Epoch 80/300] [Batch 900/938] [D loss: 0.269427] [G loss: 3.393884]\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "[Epoch 85/300] [Batch 0/938] [D loss: 0.262543] [G loss: 5.813676]\n",
            "[Epoch 85/300] [Batch 100/938] [D loss: 0.205571] [G loss: 2.508878]\n",
            "[Epoch 85/300] [Batch 200/938] [D loss: 0.333645] [G loss: 2.130635]\n",
            "[Epoch 85/300] [Batch 300/938] [D loss: 0.222877] [G loss: 2.193326]\n",
            "[Epoch 85/300] [Batch 400/938] [D loss: 0.187635] [G loss: 2.597650]\n",
            "[Epoch 85/300] [Batch 500/938] [D loss: 0.256384] [G loss: 2.326192]\n",
            "[Epoch 85/300] [Batch 600/938] [D loss: 0.235979] [G loss: 2.358520]\n",
            "[Epoch 85/300] [Batch 700/938] [D loss: 0.201798] [G loss: 2.902428]\n",
            "[Epoch 85/300] [Batch 800/938] [D loss: 0.213591] [G loss: 2.718526]\n",
            "[Epoch 85/300] [Batch 900/938] [D loss: 0.258574] [G loss: 3.339805]\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "[Epoch 90/300] [Batch 0/938] [D loss: 0.174430] [G loss: 3.029750]\n",
            "[Epoch 90/300] [Batch 100/938] [D loss: 0.106342] [G loss: 3.147142]\n",
            "[Epoch 90/300] [Batch 200/938] [D loss: 0.214294] [G loss: 3.181300]\n",
            "[Epoch 90/300] [Batch 300/938] [D loss: 0.145431] [G loss: 3.209456]\n",
            "[Epoch 90/300] [Batch 400/938] [D loss: 0.191919] [G loss: 1.893088]\n",
            "[Epoch 90/300] [Batch 500/938] [D loss: 0.290302] [G loss: 2.355891]\n",
            "[Epoch 90/300] [Batch 600/938] [D loss: 0.277097] [G loss: 4.269497]\n",
            "[Epoch 90/300] [Batch 700/938] [D loss: 0.263550] [G loss: 2.736996]\n",
            "[Epoch 90/300] [Batch 800/938] [D loss: 0.085918] [G loss: 3.159880]\n",
            "[Epoch 90/300] [Batch 900/938] [D loss: 0.275109] [G loss: 3.928002]\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "[Epoch 95/300] [Batch 0/938] [D loss: 0.259951] [G loss: 3.124549]\n",
            "[Epoch 95/300] [Batch 100/938] [D loss: 0.252788] [G loss: 3.387159]\n",
            "[Epoch 95/300] [Batch 200/938] [D loss: 0.305202] [G loss: 2.583893]\n",
            "[Epoch 95/300] [Batch 300/938] [D loss: 0.239706] [G loss: 1.809136]\n",
            "[Epoch 95/300] [Batch 400/938] [D loss: 0.331936] [G loss: 1.789348]\n",
            "[Epoch 95/300] [Batch 500/938] [D loss: 0.196615] [G loss: 3.219794]\n",
            "[Epoch 95/300] [Batch 600/938] [D loss: 0.164388] [G loss: 3.259746]\n",
            "[Epoch 95/300] [Batch 700/938] [D loss: 0.270021] [G loss: 2.589153]\n",
            "[Epoch 95/300] [Batch 800/938] [D loss: 0.242516] [G loss: 3.329484]\n",
            "[Epoch 95/300] [Batch 900/938] [D loss: 0.307196] [G loss: 2.747643]\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "[Epoch 100/300] [Batch 0/938] [D loss: 0.225342] [G loss: 2.911192]\n",
            "[Epoch 100/300] [Batch 100/938] [D loss: 0.173373] [G loss: 3.952774]\n",
            "[Epoch 100/300] [Batch 200/938] [D loss: 0.244349] [G loss: 1.977135]\n",
            "[Epoch 100/300] [Batch 300/938] [D loss: 0.287242] [G loss: 2.860949]\n",
            "[Epoch 100/300] [Batch 400/938] [D loss: 0.300788] [G loss: 2.971478]\n",
            "[Epoch 100/300] [Batch 500/938] [D loss: 0.283636] [G loss: 4.028149]\n",
            "[Epoch 100/300] [Batch 600/938] [D loss: 0.199239] [G loss: 1.966181]\n",
            "[Epoch 100/300] [Batch 700/938] [D loss: 0.294074] [G loss: 2.511482]\n",
            "[Epoch 100/300] [Batch 800/938] [D loss: 0.221943] [G loss: 2.173021]\n",
            "[Epoch 100/300] [Batch 900/938] [D loss: 0.279920] [G loss: 2.853541]\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "[Epoch 105/300] [Batch 0/938] [D loss: 0.447896] [G loss: 1.745762]\n",
            "[Epoch 105/300] [Batch 100/938] [D loss: 0.270610] [G loss: 3.401256]\n",
            "[Epoch 105/300] [Batch 200/938] [D loss: 0.326639] [G loss: 1.744800]\n",
            "[Epoch 105/300] [Batch 300/938] [D loss: 0.351225] [G loss: 2.908299]\n",
            "[Epoch 105/300] [Batch 400/938] [D loss: 0.206553] [G loss: 2.429842]\n",
            "[Epoch 105/300] [Batch 500/938] [D loss: 0.331557] [G loss: 3.601094]\n",
            "[Epoch 105/300] [Batch 600/938] [D loss: 0.294782] [G loss: 2.180050]\n",
            "[Epoch 105/300] [Batch 700/938] [D loss: 0.294593] [G loss: 3.160955]\n",
            "[Epoch 105/300] [Batch 800/938] [D loss: 0.236563] [G loss: 2.734692]\n",
            "[Epoch 105/300] [Batch 900/938] [D loss: 0.233466] [G loss: 2.398431]\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "[Epoch 110/300] [Batch 0/938] [D loss: 0.288332] [G loss: 4.154870]\n",
            "[Epoch 110/300] [Batch 100/938] [D loss: 0.226369] [G loss: 2.380270]\n",
            "[Epoch 110/300] [Batch 200/938] [D loss: 0.289102] [G loss: 1.847365]\n",
            "[Epoch 110/300] [Batch 300/938] [D loss: 0.225218] [G loss: 1.681937]\n",
            "[Epoch 110/300] [Batch 400/938] [D loss: 0.199841] [G loss: 3.766236]\n",
            "[Epoch 110/300] [Batch 500/938] [D loss: 0.288188] [G loss: 2.453588]\n",
            "[Epoch 110/300] [Batch 600/938] [D loss: 0.249962] [G loss: 2.412064]\n",
            "[Epoch 110/300] [Batch 700/938] [D loss: 0.315324] [G loss: 1.937485]\n",
            "[Epoch 110/300] [Batch 800/938] [D loss: 0.232306] [G loss: 2.597038]\n",
            "[Epoch 110/300] [Batch 900/938] [D loss: 0.302121] [G loss: 2.037682]\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "[Epoch 115/300] [Batch 0/938] [D loss: 0.330443] [G loss: 2.197617]\n",
            "[Epoch 115/300] [Batch 100/938] [D loss: 0.239838] [G loss: 3.025052]\n",
            "[Epoch 115/300] [Batch 200/938] [D loss: 0.345165] [G loss: 2.551268]\n",
            "[Epoch 115/300] [Batch 300/938] [D loss: 0.204399] [G loss: 3.006123]\n",
            "[Epoch 115/300] [Batch 400/938] [D loss: 0.244414] [G loss: 2.117633]\n",
            "[Epoch 115/300] [Batch 500/938] [D loss: 0.397510] [G loss: 2.490549]\n",
            "[Epoch 115/300] [Batch 600/938] [D loss: 0.295592] [G loss: 2.208673]\n",
            "[Epoch 115/300] [Batch 700/938] [D loss: 0.217710] [G loss: 2.241993]\n",
            "[Epoch 115/300] [Batch 800/938] [D loss: 0.251592] [G loss: 3.834851]\n",
            "[Epoch 115/300] [Batch 900/938] [D loss: 0.316049] [G loss: 2.350592]\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "[Epoch 120/300] [Batch 0/938] [D loss: 0.375665] [G loss: 3.124956]\n",
            "[Epoch 120/300] [Batch 100/938] [D loss: 0.241168] [G loss: 2.631574]\n",
            "[Epoch 120/300] [Batch 200/938] [D loss: 0.312252] [G loss: 2.292296]\n",
            "[Epoch 120/300] [Batch 300/938] [D loss: 0.136346] [G loss: 2.978638]\n",
            "[Epoch 120/300] [Batch 400/938] [D loss: 0.264937] [G loss: 2.090797]\n",
            "[Epoch 120/300] [Batch 500/938] [D loss: 0.359183] [G loss: 2.506220]\n",
            "[Epoch 120/300] [Batch 600/938] [D loss: 0.391815] [G loss: 1.621341]\n",
            "[Epoch 120/300] [Batch 700/938] [D loss: 0.253533] [G loss: 1.224889]\n",
            "[Epoch 120/300] [Batch 800/938] [D loss: 0.270557] [G loss: 2.149777]\n",
            "[Epoch 120/300] [Batch 900/938] [D loss: 0.306822] [G loss: 2.766863]\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "[Epoch 125/300] [Batch 0/938] [D loss: 0.247454] [G loss: 2.127122]\n",
            "[Epoch 125/300] [Batch 100/938] [D loss: 0.195250] [G loss: 3.292447]\n",
            "[Epoch 125/300] [Batch 200/938] [D loss: 0.294652] [G loss: 2.168164]\n",
            "[Epoch 125/300] [Batch 300/938] [D loss: 0.224522] [G loss: 1.963554]\n",
            "[Epoch 125/300] [Batch 400/938] [D loss: 0.270004] [G loss: 2.844614]\n",
            "[Epoch 125/300] [Batch 500/938] [D loss: 0.231707] [G loss: 2.764612]\n",
            "[Epoch 125/300] [Batch 600/938] [D loss: 0.357656] [G loss: 1.547026]\n",
            "[Epoch 125/300] [Batch 700/938] [D loss: 0.316532] [G loss: 4.420599]\n",
            "[Epoch 125/300] [Batch 800/938] [D loss: 0.327960] [G loss: 2.426174]\n",
            "[Epoch 125/300] [Batch 900/938] [D loss: 0.384171] [G loss: 2.696151]\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "[Epoch 130/300] [Batch 0/938] [D loss: 0.297288] [G loss: 3.060400]\n",
            "[Epoch 130/300] [Batch 100/938] [D loss: 0.351214] [G loss: 2.900308]\n",
            "[Epoch 130/300] [Batch 200/938] [D loss: 0.370950] [G loss: 1.410803]\n",
            "[Epoch 130/300] [Batch 300/938] [D loss: 0.300886] [G loss: 2.473650]\n",
            "[Epoch 130/300] [Batch 400/938] [D loss: 0.288293] [G loss: 2.757096]\n",
            "[Epoch 130/300] [Batch 500/938] [D loss: 0.476384] [G loss: 1.709557]\n",
            "[Epoch 130/300] [Batch 600/938] [D loss: 0.320681] [G loss: 1.734580]\n",
            "[Epoch 130/300] [Batch 700/938] [D loss: 0.239609] [G loss: 3.588758]\n",
            "[Epoch 130/300] [Batch 800/938] [D loss: 0.415543] [G loss: 2.572270]\n",
            "[Epoch 130/300] [Batch 900/938] [D loss: 0.299569] [G loss: 2.642529]\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "[Epoch 135/300] [Batch 0/938] [D loss: 0.258015] [G loss: 2.777926]\n",
            "[Epoch 135/300] [Batch 100/938] [D loss: 0.349383] [G loss: 2.222548]\n",
            "[Epoch 135/300] [Batch 200/938] [D loss: 0.337068] [G loss: 2.055274]\n",
            "[Epoch 135/300] [Batch 300/938] [D loss: 0.258263] [G loss: 1.989064]\n",
            "[Epoch 135/300] [Batch 400/938] [D loss: 0.377720] [G loss: 1.250259]\n",
            "[Epoch 135/300] [Batch 500/938] [D loss: 0.453782] [G loss: 2.837751]\n",
            "[Epoch 135/300] [Batch 600/938] [D loss: 0.344063] [G loss: 2.045584]\n",
            "[Epoch 135/300] [Batch 700/938] [D loss: 0.260161] [G loss: 3.403069]\n",
            "[Epoch 135/300] [Batch 800/938] [D loss: 0.346166] [G loss: 1.808376]\n",
            "[Epoch 135/300] [Batch 900/938] [D loss: 0.211177] [G loss: 2.608274]\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "[Epoch 140/300] [Batch 0/938] [D loss: 0.270132] [G loss: 3.191072]\n",
            "[Epoch 140/300] [Batch 100/938] [D loss: 0.297643] [G loss: 2.502570]\n",
            "[Epoch 140/300] [Batch 200/938] [D loss: 0.224987] [G loss: 2.032723]\n",
            "[Epoch 140/300] [Batch 300/938] [D loss: 0.186072] [G loss: 2.278211]\n",
            "[Epoch 140/300] [Batch 400/938] [D loss: 0.182812] [G loss: 2.564389]\n",
            "[Epoch 140/300] [Batch 500/938] [D loss: 0.228106] [G loss: 2.374301]\n",
            "[Epoch 140/300] [Batch 600/938] [D loss: 0.318521] [G loss: 1.502919]\n",
            "[Epoch 140/300] [Batch 700/938] [D loss: 0.412846] [G loss: 2.295552]\n",
            "[Epoch 140/300] [Batch 800/938] [D loss: 0.529047] [G loss: 1.940019]\n",
            "[Epoch 140/300] [Batch 900/938] [D loss: 0.420572] [G loss: 2.721653]\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "[Epoch 145/300] [Batch 0/938] [D loss: 0.317442] [G loss: 2.999781]\n",
            "[Epoch 145/300] [Batch 100/938] [D loss: 0.285600] [G loss: 2.729981]\n",
            "[Epoch 145/300] [Batch 200/938] [D loss: 0.322886] [G loss: 2.232541]\n",
            "[Epoch 145/300] [Batch 300/938] [D loss: 0.270410] [G loss: 2.681378]\n",
            "[Epoch 145/300] [Batch 400/938] [D loss: 0.261275] [G loss: 2.173456]\n",
            "[Epoch 145/300] [Batch 500/938] [D loss: 0.441284] [G loss: 3.039129]\n",
            "[Epoch 145/300] [Batch 600/938] [D loss: 0.237386] [G loss: 1.916661]\n",
            "[Epoch 145/300] [Batch 700/938] [D loss: 0.332475] [G loss: 2.251789]\n",
            "[Epoch 145/300] [Batch 800/938] [D loss: 0.372350] [G loss: 2.303737]\n",
            "[Epoch 145/300] [Batch 900/938] [D loss: 0.292263] [G loss: 2.578831]\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "[Epoch 150/300] [Batch 0/938] [D loss: 0.287075] [G loss: 2.773511]\n",
            "[Epoch 150/300] [Batch 100/938] [D loss: 0.326863] [G loss: 3.424313]\n",
            "[Epoch 150/300] [Batch 200/938] [D loss: 0.364586] [G loss: 2.375832]\n",
            "[Epoch 150/300] [Batch 300/938] [D loss: 0.246236] [G loss: 2.276200]\n",
            "[Epoch 150/300] [Batch 400/938] [D loss: 0.303759] [G loss: 2.098929]\n",
            "[Epoch 150/300] [Batch 500/938] [D loss: 0.303986] [G loss: 2.473666]\n",
            "[Epoch 150/300] [Batch 600/938] [D loss: 0.269520] [G loss: 2.089533]\n",
            "[Epoch 150/300] [Batch 700/938] [D loss: 0.234967] [G loss: 2.606133]\n",
            "[Epoch 150/300] [Batch 800/938] [D loss: 0.492246] [G loss: 1.571057]\n",
            "[Epoch 150/300] [Batch 900/938] [D loss: 0.323912] [G loss: 2.298773]\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "[Epoch 155/300] [Batch 0/938] [D loss: 0.395355] [G loss: 1.399024]\n",
            "[Epoch 155/300] [Batch 100/938] [D loss: 0.228524] [G loss: 2.883118]\n",
            "[Epoch 155/300] [Batch 200/938] [D loss: 0.311503] [G loss: 1.806921]\n",
            "[Epoch 155/300] [Batch 300/938] [D loss: 0.228007] [G loss: 1.752884]\n",
            "[Epoch 155/300] [Batch 400/938] [D loss: 0.255806] [G loss: 2.813903]\n",
            "[Epoch 155/300] [Batch 500/938] [D loss: 0.301117] [G loss: 1.637246]\n",
            "[Epoch 155/300] [Batch 600/938] [D loss: 0.325583] [G loss: 1.901234]\n",
            "[Epoch 155/300] [Batch 700/938] [D loss: 0.235532] [G loss: 1.954796]\n",
            "[Epoch 155/300] [Batch 800/938] [D loss: 0.442874] [G loss: 1.903412]\n",
            "[Epoch 155/300] [Batch 900/938] [D loss: 0.234810] [G loss: 3.033699]\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "[Epoch 160/300] [Batch 0/938] [D loss: 0.368294] [G loss: 3.114918]\n",
            "[Epoch 160/300] [Batch 100/938] [D loss: 0.357614] [G loss: 2.601774]\n",
            "[Epoch 160/300] [Batch 200/938] [D loss: 0.279576] [G loss: 2.024163]\n",
            "[Epoch 160/300] [Batch 300/938] [D loss: 0.242131] [G loss: 2.616861]\n",
            "[Epoch 160/300] [Batch 400/938] [D loss: 0.305798] [G loss: 2.485702]\n",
            "[Epoch 160/300] [Batch 500/938] [D loss: 0.446475] [G loss: 3.355183]\n",
            "[Epoch 160/300] [Batch 600/938] [D loss: 0.306109] [G loss: 1.416037]\n",
            "[Epoch 160/300] [Batch 700/938] [D loss: 0.218603] [G loss: 2.873833]\n",
            "[Epoch 160/300] [Batch 800/938] [D loss: 0.645822] [G loss: 1.894019]\n",
            "[Epoch 160/300] [Batch 900/938] [D loss: 0.306051] [G loss: 1.901862]\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "[Epoch 165/300] [Batch 0/938] [D loss: 0.457587] [G loss: 3.053600]\n",
            "[Epoch 165/300] [Batch 100/938] [D loss: 0.241475] [G loss: 2.335423]\n",
            "[Epoch 165/300] [Batch 200/938] [D loss: 0.304947] [G loss: 2.748521]\n",
            "[Epoch 165/300] [Batch 300/938] [D loss: 0.368391] [G loss: 2.196507]\n",
            "[Epoch 165/300] [Batch 400/938] [D loss: 0.288010] [G loss: 2.200924]\n",
            "[Epoch 165/300] [Batch 500/938] [D loss: 0.246584] [G loss: 3.101477]\n",
            "[Epoch 165/300] [Batch 600/938] [D loss: 0.418659] [G loss: 2.071517]\n",
            "[Epoch 165/300] [Batch 700/938] [D loss: 0.245652] [G loss: 2.813139]\n",
            "[Epoch 165/300] [Batch 800/938] [D loss: 0.326153] [G loss: 1.890890]\n",
            "[Epoch 165/300] [Batch 900/938] [D loss: 0.250935] [G loss: 2.829581]\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "[Epoch 170/300] [Batch 0/938] [D loss: 0.319003] [G loss: 2.087354]\n",
            "[Epoch 170/300] [Batch 100/938] [D loss: 0.248308] [G loss: 2.516239]\n",
            "[Epoch 170/300] [Batch 200/938] [D loss: 0.416278] [G loss: 1.627552]\n",
            "[Epoch 170/300] [Batch 300/938] [D loss: 0.381429] [G loss: 3.135097]\n",
            "[Epoch 170/300] [Batch 400/938] [D loss: 0.285067] [G loss: 1.827942]\n",
            "[Epoch 170/300] [Batch 500/938] [D loss: 0.527353] [G loss: 2.067878]\n",
            "[Epoch 170/300] [Batch 600/938] [D loss: 0.403043] [G loss: 1.801946]\n",
            "[Epoch 170/300] [Batch 700/938] [D loss: 0.302148] [G loss: 2.758254]\n",
            "[Epoch 170/300] [Batch 800/938] [D loss: 0.490789] [G loss: 2.344860]\n",
            "[Epoch 170/300] [Batch 900/938] [D loss: 0.298531] [G loss: 2.317481]\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "[Epoch 175/300] [Batch 0/938] [D loss: 0.313398] [G loss: 3.607649]\n",
            "[Epoch 175/300] [Batch 100/938] [D loss: 0.255602] [G loss: 2.941889]\n",
            "[Epoch 175/300] [Batch 200/938] [D loss: 0.488290] [G loss: 2.248091]\n",
            "[Epoch 175/300] [Batch 300/938] [D loss: 0.214490] [G loss: 2.413766]\n",
            "[Epoch 175/300] [Batch 400/938] [D loss: 0.310637] [G loss: 3.110794]\n",
            "[Epoch 175/300] [Batch 500/938] [D loss: 0.307461] [G loss: 2.939633]\n",
            "[Epoch 175/300] [Batch 600/938] [D loss: 0.269874] [G loss: 1.749701]\n",
            "[Epoch 175/300] [Batch 700/938] [D loss: 0.218499] [G loss: 1.995043]\n",
            "[Epoch 175/300] [Batch 800/938] [D loss: 0.264461] [G loss: 1.843152]\n",
            "[Epoch 175/300] [Batch 900/938] [D loss: 0.250661] [G loss: 2.656931]\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "[Epoch 180/300] [Batch 0/938] [D loss: 0.334087] [G loss: 2.437138]\n",
            "[Epoch 180/300] [Batch 100/938] [D loss: 0.318847] [G loss: 2.245996]\n",
            "[Epoch 180/300] [Batch 200/938] [D loss: 0.395452] [G loss: 2.052480]\n",
            "[Epoch 180/300] [Batch 300/938] [D loss: 0.232988] [G loss: 3.414679]\n",
            "[Epoch 180/300] [Batch 400/938] [D loss: 0.243641] [G loss: 2.680991]\n",
            "[Epoch 180/300] [Batch 500/938] [D loss: 0.368362] [G loss: 2.390133]\n",
            "[Epoch 180/300] [Batch 600/938] [D loss: 0.320950] [G loss: 2.277587]\n",
            "[Epoch 180/300] [Batch 700/938] [D loss: 0.232367] [G loss: 2.722849]\n",
            "[Epoch 180/300] [Batch 800/938] [D loss: 0.434171] [G loss: 1.527804]\n",
            "[Epoch 180/300] [Batch 900/938] [D loss: 0.387014] [G loss: 2.731604]\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "[Epoch 185/300] [Batch 0/938] [D loss: 0.361352] [G loss: 2.365567]\n",
            "[Epoch 185/300] [Batch 100/938] [D loss: 0.331531] [G loss: 2.318192]\n",
            "[Epoch 185/300] [Batch 200/938] [D loss: 0.251626] [G loss: 2.856658]\n",
            "[Epoch 185/300] [Batch 300/938] [D loss: 0.322509] [G loss: 2.307865]\n",
            "[Epoch 185/300] [Batch 400/938] [D loss: 0.287735] [G loss: 2.697680]\n",
            "[Epoch 185/300] [Batch 500/938] [D loss: 0.334423] [G loss: 2.058778]\n",
            "[Epoch 185/300] [Batch 600/938] [D loss: 0.285170] [G loss: 2.335251]\n",
            "[Epoch 185/300] [Batch 700/938] [D loss: 0.287096] [G loss: 2.012434]\n",
            "[Epoch 185/300] [Batch 800/938] [D loss: 0.336444] [G loss: 2.877819]\n",
            "[Epoch 185/300] [Batch 900/938] [D loss: 0.363225] [G loss: 1.859623]\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "[Epoch 190/300] [Batch 0/938] [D loss: 0.308077] [G loss: 2.859304]\n",
            "[Epoch 190/300] [Batch 100/938] [D loss: 0.283997] [G loss: 2.448318]\n",
            "[Epoch 190/300] [Batch 200/938] [D loss: 0.386573] [G loss: 2.244817]\n",
            "[Epoch 190/300] [Batch 300/938] [D loss: 0.321112] [G loss: 2.102290]\n",
            "[Epoch 190/300] [Batch 400/938] [D loss: 0.277525] [G loss: 2.363240]\n",
            "[Epoch 190/300] [Batch 500/938] [D loss: 0.308676] [G loss: 1.854829]\n",
            "[Epoch 190/300] [Batch 600/938] [D loss: 0.322047] [G loss: 1.446749]\n",
            "[Epoch 190/300] [Batch 700/938] [D loss: 0.326346] [G loss: 2.043328]\n",
            "[Epoch 190/300] [Batch 800/938] [D loss: 0.503831] [G loss: 1.726575]\n",
            "[Epoch 190/300] [Batch 900/938] [D loss: 0.318369] [G loss: 2.305782]\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "[Epoch 195/300] [Batch 0/938] [D loss: 0.293449] [G loss: 2.386962]\n",
            "[Epoch 195/300] [Batch 100/938] [D loss: 0.292846] [G loss: 2.835931]\n",
            "[Epoch 195/300] [Batch 200/938] [D loss: 0.419821] [G loss: 1.673318]\n",
            "[Epoch 195/300] [Batch 300/938] [D loss: 0.247501] [G loss: 2.050343]\n",
            "[Epoch 195/300] [Batch 400/938] [D loss: 0.350917] [G loss: 1.754924]\n",
            "[Epoch 195/300] [Batch 500/938] [D loss: 0.342290] [G loss: 1.241744]\n",
            "[Epoch 195/300] [Batch 600/938] [D loss: 0.380155] [G loss: 1.897227]\n",
            "[Epoch 195/300] [Batch 700/938] [D loss: 0.348377] [G loss: 1.814425]\n",
            "[Epoch 195/300] [Batch 800/938] [D loss: 0.374937] [G loss: 2.464286]\n",
            "[Epoch 195/300] [Batch 900/938] [D loss: 0.389163] [G loss: 1.891204]\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "[Epoch 200/300] [Batch 0/938] [D loss: 0.351054] [G loss: 2.320643]\n",
            "[Epoch 200/300] [Batch 100/938] [D loss: 0.254227] [G loss: 1.787796]\n",
            "[Epoch 200/300] [Batch 200/938] [D loss: 0.359844] [G loss: 2.806077]\n",
            "[Epoch 200/300] [Batch 300/938] [D loss: 0.235831] [G loss: 3.301029]\n",
            "[Epoch 200/300] [Batch 400/938] [D loss: 0.282227] [G loss: 2.131603]\n",
            "[Epoch 200/300] [Batch 500/938] [D loss: 0.365236] [G loss: 1.736661]\n",
            "[Epoch 200/300] [Batch 600/938] [D loss: 0.263907] [G loss: 2.573081]\n",
            "[Epoch 200/300] [Batch 700/938] [D loss: 0.303681] [G loss: 2.674663]\n",
            "[Epoch 200/300] [Batch 800/938] [D loss: 0.322378] [G loss: 2.246835]\n",
            "[Epoch 200/300] [Batch 900/938] [D loss: 0.342691] [G loss: 2.652536]\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "[Epoch 205/300] [Batch 0/938] [D loss: 0.375546] [G loss: 2.610171]\n",
            "[Epoch 205/300] [Batch 100/938] [D loss: 0.280248] [G loss: 2.856539]\n",
            "[Epoch 205/300] [Batch 200/938] [D loss: 0.327778] [G loss: 1.658219]\n",
            "[Epoch 205/300] [Batch 300/938] [D loss: 0.207102] [G loss: 2.913732]\n",
            "[Epoch 205/300] [Batch 400/938] [D loss: 0.329375] [G loss: 2.663408]\n",
            "[Epoch 205/300] [Batch 500/938] [D loss: 0.402053] [G loss: 1.979102]\n",
            "[Epoch 205/300] [Batch 600/938] [D loss: 0.327176] [G loss: 1.993069]\n",
            "[Epoch 205/300] [Batch 700/938] [D loss: 0.277938] [G loss: 2.461836]\n",
            "[Epoch 205/300] [Batch 800/938] [D loss: 0.380398] [G loss: 2.558104]\n",
            "[Epoch 205/300] [Batch 900/938] [D loss: 0.298799] [G loss: 2.503791]\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "[Epoch 210/300] [Batch 0/938] [D loss: 0.390979] [G loss: 3.182202]\n",
            "[Epoch 210/300] [Batch 100/938] [D loss: 0.239982] [G loss: 2.690777]\n",
            "[Epoch 210/300] [Batch 200/938] [D loss: 0.338956] [G loss: 2.394122]\n",
            "[Epoch 210/300] [Batch 300/938] [D loss: 0.179332] [G loss: 2.981173]\n",
            "[Epoch 210/300] [Batch 400/938] [D loss: 0.265623] [G loss: 2.731356]\n",
            "[Epoch 210/300] [Batch 500/938] [D loss: 0.356571] [G loss: 1.458666]\n",
            "[Epoch 210/300] [Batch 600/938] [D loss: 0.314646] [G loss: 2.260325]\n",
            "[Epoch 210/300] [Batch 700/938] [D loss: 0.331765] [G loss: 1.977087]\n",
            "[Epoch 210/300] [Batch 800/938] [D loss: 0.340395] [G loss: 2.823973]\n",
            "[Epoch 210/300] [Batch 900/938] [D loss: 0.343356] [G loss: 2.287286]\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "[Epoch 215/300] [Batch 0/938] [D loss: 0.330015] [G loss: 2.491307]\n",
            "[Epoch 215/300] [Batch 100/938] [D loss: 0.285941] [G loss: 2.548006]\n",
            "[Epoch 215/300] [Batch 200/938] [D loss: 0.315522] [G loss: 2.028949]\n",
            "[Epoch 215/300] [Batch 300/938] [D loss: 0.213687] [G loss: 2.316236]\n",
            "[Epoch 215/300] [Batch 400/938] [D loss: 0.250204] [G loss: 2.588284]\n",
            "[Epoch 215/300] [Batch 500/938] [D loss: 0.424197] [G loss: 2.071128]\n",
            "[Epoch 215/300] [Batch 600/938] [D loss: 0.390426] [G loss: 2.159103]\n",
            "[Epoch 215/300] [Batch 700/938] [D loss: 0.357070] [G loss: 2.043045]\n",
            "[Epoch 215/300] [Batch 800/938] [D loss: 0.411021] [G loss: 2.096940]\n",
            "[Epoch 215/300] [Batch 900/938] [D loss: 0.295498] [G loss: 2.353540]\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "[Epoch 220/300] [Batch 0/938] [D loss: 0.421377] [G loss: 1.859791]\n",
            "[Epoch 220/300] [Batch 100/938] [D loss: 0.341185] [G loss: 1.790788]\n",
            "[Epoch 220/300] [Batch 200/938] [D loss: 0.382235] [G loss: 1.926677]\n",
            "[Epoch 220/300] [Batch 300/938] [D loss: 0.360971] [G loss: 2.323758]\n",
            "[Epoch 220/300] [Batch 400/938] [D loss: 0.293642] [G loss: 2.333580]\n",
            "[Epoch 220/300] [Batch 500/938] [D loss: 0.349003] [G loss: 1.424282]\n",
            "[Epoch 220/300] [Batch 600/938] [D loss: 0.359775] [G loss: 1.875805]\n",
            "[Epoch 220/300] [Batch 700/938] [D loss: 0.267908] [G loss: 1.819432]\n",
            "[Epoch 220/300] [Batch 800/938] [D loss: 0.321647] [G loss: 2.305767]\n",
            "[Epoch 220/300] [Batch 900/938] [D loss: 0.275783] [G loss: 2.300293]\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "[Epoch 225/300] [Batch 0/938] [D loss: 0.250970] [G loss: 2.277934]\n",
            "[Epoch 225/300] [Batch 100/938] [D loss: 0.327167] [G loss: 2.871888]\n",
            "[Epoch 225/300] [Batch 200/938] [D loss: 0.574437] [G loss: 2.241238]\n",
            "[Epoch 225/300] [Batch 300/938] [D loss: 0.423044] [G loss: 2.840635]\n",
            "[Epoch 225/300] [Batch 400/938] [D loss: 0.303400] [G loss: 2.401037]\n",
            "[Epoch 225/300] [Batch 500/938] [D loss: 0.372240] [G loss: 1.505630]\n",
            "[Epoch 225/300] [Batch 600/938] [D loss: 0.380933] [G loss: 1.901914]\n",
            "[Epoch 225/300] [Batch 700/938] [D loss: 0.283023] [G loss: 2.002561]\n",
            "[Epoch 225/300] [Batch 800/938] [D loss: 0.522800] [G loss: 2.461944]\n",
            "[Epoch 225/300] [Batch 900/938] [D loss: 0.384743] [G loss: 1.836766]\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "[Epoch 230/300] [Batch 0/938] [D loss: 0.386734] [G loss: 2.098300]\n",
            "[Epoch 230/300] [Batch 100/938] [D loss: 0.255744] [G loss: 1.845853]\n",
            "[Epoch 230/300] [Batch 200/938] [D loss: 0.450556] [G loss: 2.363068]\n",
            "[Epoch 230/300] [Batch 300/938] [D loss: 0.244228] [G loss: 3.000784]\n",
            "[Epoch 230/300] [Batch 400/938] [D loss: 0.265515] [G loss: 2.356149]\n",
            "[Epoch 230/300] [Batch 500/938] [D loss: 0.350365] [G loss: 1.295518]\n",
            "[Epoch 230/300] [Batch 600/938] [D loss: 0.269527] [G loss: 2.492025]\n",
            "[Epoch 230/300] [Batch 700/938] [D loss: 0.266643] [G loss: 2.607864]\n",
            "[Epoch 230/300] [Batch 800/938] [D loss: 0.517300] [G loss: 2.190879]\n",
            "[Epoch 230/300] [Batch 900/938] [D loss: 0.254896] [G loss: 2.458046]\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "[Epoch 235/300] [Batch 0/938] [D loss: 0.282080] [G loss: 2.700032]\n",
            "[Epoch 235/300] [Batch 100/938] [D loss: 0.370885] [G loss: 2.157762]\n",
            "[Epoch 235/300] [Batch 200/938] [D loss: 0.302120] [G loss: 1.863633]\n",
            "[Epoch 235/300] [Batch 300/938] [D loss: 0.268659] [G loss: 2.003944]\n",
            "[Epoch 235/300] [Batch 400/938] [D loss: 0.284268] [G loss: 2.101908]\n",
            "[Epoch 235/300] [Batch 500/938] [D loss: 0.349323] [G loss: 1.516474]\n",
            "[Epoch 235/300] [Batch 600/938] [D loss: 0.447364] [G loss: 2.330382]\n",
            "[Epoch 235/300] [Batch 700/938] [D loss: 0.352878] [G loss: 2.130166]\n",
            "[Epoch 235/300] [Batch 800/938] [D loss: 0.453498] [G loss: 2.666763]\n",
            "[Epoch 235/300] [Batch 900/938] [D loss: 0.371868] [G loss: 1.732761]\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "[Epoch 240/300] [Batch 0/938] [D loss: 0.323364] [G loss: 1.798717]\n",
            "[Epoch 240/300] [Batch 100/938] [D loss: 0.245499] [G loss: 2.324336]\n",
            "[Epoch 240/300] [Batch 200/938] [D loss: 0.382328] [G loss: 2.399002]\n",
            "[Epoch 240/300] [Batch 300/938] [D loss: 0.250110] [G loss: 2.579583]\n",
            "[Epoch 240/300] [Batch 400/938] [D loss: 0.286257] [G loss: 2.538451]\n",
            "[Epoch 240/300] [Batch 500/938] [D loss: 0.425468] [G loss: 2.101501]\n",
            "[Epoch 240/300] [Batch 600/938] [D loss: 0.374622] [G loss: 1.671215]\n",
            "[Epoch 240/300] [Batch 700/938] [D loss: 0.259408] [G loss: 2.321750]\n",
            "[Epoch 240/300] [Batch 800/938] [D loss: 0.350007] [G loss: 2.687207]\n",
            "[Epoch 240/300] [Batch 900/938] [D loss: 0.288632] [G loss: 2.471614]\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "[Epoch 245/300] [Batch 0/938] [D loss: 0.294614] [G loss: 2.201838]\n",
            "[Epoch 245/300] [Batch 100/938] [D loss: 0.275519] [G loss: 2.357210]\n",
            "[Epoch 245/300] [Batch 200/938] [D loss: 0.324117] [G loss: 1.668076]\n",
            "[Epoch 245/300] [Batch 300/938] [D loss: 0.309118] [G loss: 2.217415]\n",
            "[Epoch 245/300] [Batch 400/938] [D loss: 0.354763] [G loss: 2.054853]\n",
            "[Epoch 245/300] [Batch 500/938] [D loss: 0.356220] [G loss: 2.077630]\n",
            "[Epoch 245/300] [Batch 600/938] [D loss: 0.399604] [G loss: 1.993906]\n",
            "[Epoch 245/300] [Batch 700/938] [D loss: 0.312646] [G loss: 2.010744]\n",
            "[Epoch 245/300] [Batch 800/938] [D loss: 0.498488] [G loss: 2.078049]\n",
            "[Epoch 245/300] [Batch 900/938] [D loss: 0.274953] [G loss: 1.586201]\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "[Epoch 250/300] [Batch 0/938] [D loss: 0.323484] [G loss: 2.436533]\n",
            "[Epoch 250/300] [Batch 100/938] [D loss: 0.282174] [G loss: 2.007704]\n",
            "[Epoch 250/300] [Batch 200/938] [D loss: 0.337040] [G loss: 1.783372]\n",
            "[Epoch 250/300] [Batch 300/938] [D loss: 0.298438] [G loss: 3.109236]\n",
            "[Epoch 250/300] [Batch 400/938] [D loss: 0.273242] [G loss: 2.040931]\n",
            "[Epoch 250/300] [Batch 500/938] [D loss: 0.451226] [G loss: 1.300378]\n",
            "[Epoch 250/300] [Batch 600/938] [D loss: 0.379428] [G loss: 2.022603]\n",
            "[Epoch 250/300] [Batch 700/938] [D loss: 0.388510] [G loss: 1.903533]\n",
            "[Epoch 250/300] [Batch 800/938] [D loss: 0.473100] [G loss: 2.265612]\n",
            "[Epoch 250/300] [Batch 900/938] [D loss: 0.233631] [G loss: 1.806013]\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "[Epoch 255/300] [Batch 0/938] [D loss: 0.353100] [G loss: 1.805137]\n",
            "[Epoch 255/300] [Batch 100/938] [D loss: 0.366273] [G loss: 2.005099]\n",
            "[Epoch 255/300] [Batch 200/938] [D loss: 0.417014] [G loss: 1.985133]\n",
            "[Epoch 255/300] [Batch 300/938] [D loss: 0.301915] [G loss: 2.179885]\n",
            "[Epoch 255/300] [Batch 400/938] [D loss: 0.332844] [G loss: 2.394543]\n",
            "[Epoch 255/300] [Batch 500/938] [D loss: 0.480686] [G loss: 1.522054]\n",
            "[Epoch 255/300] [Batch 600/938] [D loss: 0.424326] [G loss: 1.467167]\n",
            "[Epoch 255/300] [Batch 700/938] [D loss: 0.305109] [G loss: 2.068622]\n",
            "[Epoch 255/300] [Batch 800/938] [D loss: 0.267881] [G loss: 2.091016]\n",
            "[Epoch 255/300] [Batch 900/938] [D loss: 0.319433] [G loss: 1.679635]\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "[Epoch 260/300] [Batch 0/938] [D loss: 0.368061] [G loss: 1.889243]\n",
            "[Epoch 260/300] [Batch 100/938] [D loss: 0.229291] [G loss: 2.289390]\n",
            "[Epoch 260/300] [Batch 200/938] [D loss: 0.408045] [G loss: 2.076888]\n",
            "[Epoch 260/300] [Batch 300/938] [D loss: 0.261136] [G loss: 2.062402]\n",
            "[Epoch 260/300] [Batch 400/938] [D loss: 0.287301] [G loss: 2.339051]\n",
            "[Epoch 260/300] [Batch 500/938] [D loss: 0.428400] [G loss: 1.186210]\n",
            "[Epoch 260/300] [Batch 600/938] [D loss: 0.507932] [G loss: 2.514704]\n",
            "[Epoch 260/300] [Batch 700/938] [D loss: 0.309061] [G loss: 2.310853]\n",
            "[Epoch 260/300] [Batch 800/938] [D loss: 0.411692] [G loss: 1.859067]\n",
            "[Epoch 260/300] [Batch 900/938] [D loss: 0.364645] [G loss: 1.779176]\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "[Epoch 265/300] [Batch 0/938] [D loss: 0.362021] [G loss: 2.149768]\n",
            "[Epoch 265/300] [Batch 100/938] [D loss: 0.253598] [G loss: 1.394131]\n",
            "[Epoch 265/300] [Batch 200/938] [D loss: 0.392627] [G loss: 1.623924]\n",
            "[Epoch 265/300] [Batch 300/938] [D loss: 0.285701] [G loss: 2.887369]\n",
            "[Epoch 265/300] [Batch 400/938] [D loss: 0.307755] [G loss: 2.584299]\n",
            "[Epoch 265/300] [Batch 500/938] [D loss: 0.419486] [G loss: 1.520575]\n",
            "[Epoch 265/300] [Batch 600/938] [D loss: 0.398807] [G loss: 2.211333]\n",
            "[Epoch 265/300] [Batch 700/938] [D loss: 0.250513] [G loss: 2.095833]\n",
            "[Epoch 265/300] [Batch 800/938] [D loss: 0.246258] [G loss: 2.715808]\n",
            "[Epoch 265/300] [Batch 900/938] [D loss: 0.355294] [G loss: 2.534471]\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "[Epoch 270/300] [Batch 0/938] [D loss: 0.320604] [G loss: 2.486469]\n",
            "[Epoch 270/300] [Batch 100/938] [D loss: 0.238763] [G loss: 2.523359]\n",
            "[Epoch 270/300] [Batch 200/938] [D loss: 0.362886] [G loss: 2.648550]\n",
            "[Epoch 270/300] [Batch 300/938] [D loss: 0.312665] [G loss: 2.625172]\n",
            "[Epoch 270/300] [Batch 400/938] [D loss: 0.349481] [G loss: 2.118993]\n",
            "[Epoch 270/300] [Batch 500/938] [D loss: 0.432464] [G loss: 1.521182]\n",
            "[Epoch 270/300] [Batch 600/938] [D loss: 0.403375] [G loss: 2.085562]\n",
            "[Epoch 270/300] [Batch 700/938] [D loss: 0.335663] [G loss: 2.738495]\n",
            "[Epoch 270/300] [Batch 800/938] [D loss: 0.329652] [G loss: 1.967334]\n",
            "[Epoch 270/300] [Batch 900/938] [D loss: 0.296643] [G loss: 1.799017]\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "[Epoch 275/300] [Batch 0/938] [D loss: 0.296007] [G loss: 2.773160]\n",
            "[Epoch 275/300] [Batch 100/938] [D loss: 0.371467] [G loss: 2.274089]\n",
            "[Epoch 275/300] [Batch 200/938] [D loss: 0.287086] [G loss: 1.916352]\n",
            "[Epoch 275/300] [Batch 300/938] [D loss: 0.310811] [G loss: 2.343447]\n",
            "[Epoch 275/300] [Batch 400/938] [D loss: 0.255404] [G loss: 2.376723]\n",
            "[Epoch 275/300] [Batch 500/938] [D loss: 0.454911] [G loss: 1.726160]\n",
            "[Epoch 275/300] [Batch 600/938] [D loss: 0.368255] [G loss: 2.327673]\n",
            "[Epoch 275/300] [Batch 700/938] [D loss: 0.360134] [G loss: 2.152952]\n",
            "[Epoch 275/300] [Batch 800/938] [D loss: 0.290377] [G loss: 2.468098]\n",
            "[Epoch 275/300] [Batch 900/938] [D loss: 0.372223] [G loss: 2.177395]\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "[Epoch 280/300] [Batch 0/938] [D loss: 0.354925] [G loss: 2.269387]\n",
            "[Epoch 280/300] [Batch 100/938] [D loss: 0.274941] [G loss: 2.139750]\n",
            "[Epoch 280/300] [Batch 200/938] [D loss: 0.375059] [G loss: 1.721863]\n",
            "[Epoch 280/300] [Batch 300/938] [D loss: 0.263032] [G loss: 2.538251]\n",
            "[Epoch 280/300] [Batch 400/938] [D loss: 0.246141] [G loss: 2.529849]\n",
            "[Epoch 280/300] [Batch 500/938] [D loss: 0.374597] [G loss: 1.471737]\n",
            "[Epoch 280/300] [Batch 600/938] [D loss: 0.322197] [G loss: 1.989515]\n",
            "[Epoch 280/300] [Batch 700/938] [D loss: 0.388596] [G loss: 2.198767]\n",
            "[Epoch 280/300] [Batch 800/938] [D loss: 0.402077] [G loss: 3.166358]\n",
            "[Epoch 280/300] [Batch 900/938] [D loss: 0.292720] [G loss: 2.395499]\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "[Epoch 285/300] [Batch 0/938] [D loss: 0.308062] [G loss: 2.419833]\n",
            "[Epoch 285/300] [Batch 100/938] [D loss: 0.296271] [G loss: 1.613903]\n",
            "[Epoch 285/300] [Batch 200/938] [D loss: 0.360493] [G loss: 2.094663]\n",
            "[Epoch 285/300] [Batch 300/938] [D loss: 0.341395] [G loss: 2.365795]\n",
            "[Epoch 285/300] [Batch 400/938] [D loss: 0.221550] [G loss: 2.286711]\n",
            "[Epoch 285/300] [Batch 500/938] [D loss: 0.398875] [G loss: 2.009170]\n",
            "[Epoch 285/300] [Batch 600/938] [D loss: 0.354343] [G loss: 2.734065]\n",
            "[Epoch 285/300] [Batch 700/938] [D loss: 0.361152] [G loss: 1.513748]\n",
            "[Epoch 285/300] [Batch 800/938] [D loss: 0.418153] [G loss: 2.264617]\n",
            "[Epoch 285/300] [Batch 900/938] [D loss: 0.319663] [G loss: 2.094492]\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "[Epoch 290/300] [Batch 0/938] [D loss: 0.305841] [G loss: 2.302452]\n",
            "[Epoch 290/300] [Batch 100/938] [D loss: 0.257782] [G loss: 2.328149]\n",
            "[Epoch 290/300] [Batch 200/938] [D loss: 0.356554] [G loss: 1.882596]\n",
            "[Epoch 290/300] [Batch 300/938] [D loss: 0.347262] [G loss: 2.452752]\n",
            "[Epoch 290/300] [Batch 400/938] [D loss: 0.251078] [G loss: 1.811435]\n",
            "[Epoch 290/300] [Batch 500/938] [D loss: 0.377368] [G loss: 1.438651]\n",
            "[Epoch 290/300] [Batch 600/938] [D loss: 0.386893] [G loss: 2.061844]\n",
            "[Epoch 290/300] [Batch 700/938] [D loss: 0.294303] [G loss: 2.567844]\n",
            "[Epoch 290/300] [Batch 800/938] [D loss: 0.275174] [G loss: 2.701027]\n",
            "[Epoch 290/300] [Batch 900/938] [D loss: 0.319422] [G loss: 1.993476]\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "[Epoch 295/300] [Batch 0/938] [D loss: 0.376684] [G loss: 2.186255]\n",
            "[Epoch 295/300] [Batch 100/938] [D loss: 0.243409] [G loss: 2.092362]\n",
            "[Epoch 295/300] [Batch 200/938] [D loss: 0.451946] [G loss: 1.938755]\n",
            "[Epoch 295/300] [Batch 300/938] [D loss: 0.208720] [G loss: 2.215776]\n",
            "[Epoch 295/300] [Batch 400/938] [D loss: 0.230082] [G loss: 2.224304]\n",
            "[Epoch 295/300] [Batch 500/938] [D loss: 0.390946] [G loss: 1.324284]\n",
            "[Epoch 295/300] [Batch 600/938] [D loss: 0.310501] [G loss: 1.874171]\n",
            "[Epoch 295/300] [Batch 700/938] [D loss: 0.248177] [G loss: 2.698979]\n",
            "[Epoch 295/300] [Batch 800/938] [D loss: 0.321843] [G loss: 2.415862]\n",
            "[Epoch 295/300] [Batch 900/938] [D loss: 0.263013] [G loss: 1.641226]\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_7s6WBxhgjK",
        "colab_type": "code",
        "outputId": "1bc9937d-2bd9-43dd-9ea7-bb3c74ae8785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "gen.eval()\n",
        "images = []\n",
        "for i in range(20):\n",
        "  pil = transforms.ToPILImage(mode='L')(img.cpu().view(-1,28,28))\n",
        "  img = gen(torch.randn((1,latent_dim)).to(device))\n",
        "  images.append(images)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5b38f066a482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gen' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDjjeFCnKIBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "30f04dd8-ef2b-4d32-fdf2-e14920150451"
      },
      "source": [
        "import os\n",
        "\n",
        "os.mkdir(\"generated_images\")\n",
        "i = 1\n",
        "for img in images:\n",
        "  img.save(\"generated_images/img_{}.jpg\".format(i))\n",
        "  i += 1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-132879249002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generated_images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'generated_images'"
          ]
        }
      ]
    }
  ]
}